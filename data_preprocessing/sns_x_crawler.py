import requests
import pandas as pd
import json
import re
import html
from datetime import datetime, timedelta

BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAPiK3AEAAAAAQQbgHy9F0QmH3yIiGIBxcHlsGHo%3DtU20amYMVz9sNCHn53oRZE95b1djcQpKdZXVtMH6SSb3zAS3YW'


def collect_tweets(query, max_results=100, start_date=None, end_date=None):
    """íŠ¸ìœ„í„° ë°ì´í„° ìˆ˜ì§‘"""

    # ë¦¬íŠ¸ìœ—ë§Œ ì œì™¸ (ì¸ìš© íŠ¸ìœ—ì€ í¬í•¨)
    enhanced_query = f'{query} -is:retweet'

    url = 'https://api.twitter.com/2/tweets/search/recent'
    headers = {
        'Authorization': f'Bearer {BEARER_TOKEN}',
        'Content-Type': 'application/json'
    }

    # ë‚ ì§œ ì„¤ì •
    if start_date:
        start_time_str = start_date + 'T00:00:00Z'
    else:
        start_time_str = None

    # ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:
    if end_date:
        end_time_str = end_date + 'T23:59:59Z'
    else:
        # í˜„ì¬ ì‹œê°„ì—ì„œ 1ë¶„ ì „ìœ¼ë¡œ ì„¤ì •
        end_time = datetime.utcnow() - timedelta(minutes=1)
        end_time_str = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')

    params = {
        'query': enhanced_query,
        'max_results': min(max_results, 50),  # API í•œê³„
        'tweet.fields': 'text,created_at,public_metrics,lang',
        'expansions': 'author_id',
        'user.fields': 'public_metrics'
    }

    # ë‚ ì§œ ë²”ìœ„ ì¶”ê°€
    if start_time_str:
        params['start_time'] = start_time_str
    if end_time_str:
        params['end_time'] = end_time_str

    print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {enhanced_query}")
    if start_date:
        print(f"ê²€ìƒ‰ ê¸°ê°„: {start_date} ~ {end_date if end_date else 'í˜„ì¬'}")

    all_tweets = []
    seen_texts = set()  # ì¤‘ë³µ í…ìŠ¤íŠ¸ ë°©ì§€

    response = requests.get(url, headers=headers, params=params)

    if response.status_code == 200:
        data = response.json()
        tweets = data.get('data', [])
        users = {user['id']: user for user in data.get('includes', {}).get('users', [])}

        print(f"âœ… {len(tweets)}ê°œ íŠ¸ìœ— ìˆ˜ì§‘ ì™„ë£Œ")

        for tweet in tweets:
            text = tweet['text'].strip()
            text = html.unescape(text)  # HTML ì—”í‹°í‹° ë””ì½”ë”© (&quot; ë“±)
            text = re.sub(r'http[s]?://[^\s]+', '', text)  # URL ì œê±°
            text = re.sub(r'[^\w\sê°€-í£#@]', ' ', text)  # í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±, #, @ ë§Œ ë‚¨ê¸°ê¸°
            text = re.sub(r'\s+', ' ', text).strip()  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€ê²½

            # ì¤‘ë³µ í…ìŠ¤íŠ¸ ì œê±°
            if text in seen_texts:
                continue
            seen_texts.add(text)

            # ë´‡ ê³„ì •ì´ë‚˜ ë§í¬ë§Œ ìˆëŠ” íŠ¸ìœ— í•„í„°ë§
            if (len(text) < 10 or  # ë„ˆë¬´ ì§§ì€ íŠ¸ìœ—
                    text.count('https://') > 1 or  # ë§í¬ë§Œ ì—¬ëŸ¬ ê°œ
                    any(bot_keyword in text.lower() for bot_keyword in ['bot', 'ìë™', 'automatic'])):
                continue

            # ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            author_id = tweet['author_id']
            user_info = users.get(author_id, {})

            tweet_data = {
                'id': tweet['id'],
                'text': text,
                'created_at': tweet['created_at'],
                'lang': tweet.get('lang', 'unknown'),
                'like_count': tweet['public_metrics']['like_count'],
                'retweet_count': tweet['public_metrics']['retweet_count'],
                'reply_count': tweet['public_metrics']['reply_count'],
                'quote_count': tweet['public_metrics']['quote_count'],
                'author_followers': user_info.get('public_metrics', {}).get('followers_count', 0),
                'author_following': user_info.get('public_metrics', {}).get('following_count', 0)
            }

            all_tweets.append(tweet_data)

        # í•œêµ­ì–´ íŠ¸ìœ—ë§Œ í•„í„°ë§
        korean_tweets = [t for t in all_tweets if t['lang'] in ['ko', 'unknown']]

        print(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŠ¸ìœ—: {len(korean_tweets)}ê°œ")
        print(f"ì¤‘ë³µ ì œê±° ì™„ë£Œ")

        return korean_tweets

    else:
        print(f"âŒ API ì˜¤ë¥˜ {response.status_code}: {response.text}")
        return []


def save_tweets(tweets, filename='twitter_data.json'):
    """íŠ¸ìœ— ë°ì´í„° ì €ì¥"""
    if not tweets:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # JSON ì €ì¥ (ì›ë³¸ ë°ì´í„°)
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(tweets, f, indent=2, ensure_ascii=False)

    # CSV ì €ì¥ (ë¶„ì„ìš©)
    df = pd.DataFrame(tweets)
    csv_filename = filename.replace('.json', '.csv')
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')

    print(f"JSON ì €ì¥: {filename}")
    print(f"CSV ì €ì¥: {csv_filename}")

    # ë¯¸ë¦¬ë³´ê¸°
    print(f"\nìˆ˜ì§‘ëœ íŠ¸ìœ— ë¯¸ë¦¬ë³´ê¸°:")
    for i, tweet in enumerate(tweets[:3]):
        print(f"[{i + 1}] {tweet['text'][:100]}...")
        print(f"    ğŸ‘ {tweet['like_count']} | ğŸ”„ {tweet['retweet_count']} | ğŸ‘¥ {tweet['author_followers']}ëª…")
        print()


def analyze_tweets_preview(tweets):
    """ê°„ë‹¨í•œ íŠ¸ìœ— ë¶„ì„ ë¯¸ë¦¬ë³´ê¸°"""
    if not tweets:
        return

    total = len(tweets)
    avg_likes = sum(t['like_count'] for t in tweets) / total
    avg_retweets = sum(t['retweet_count'] for t in tweets) / total

    print("=" * 50)
    print("ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    print(f"ì´ íŠ¸ìœ— ìˆ˜: {total}ê°œ")
    print(f"í‰ê·  ì¢‹ì•„ìš”: {avg_likes:.1f}ê°œ")
    print(f"í‰ê·  ë¦¬íŠ¸ìœ—: {avg_retweets:.1f}ê°œ")
    print(f"ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


# ì‚¬ìš©ë²•
if __name__ == '__main__':
    # ë°ì´ì‹ìŠ¤ ë³¸ì¸í™•ì¸ ì´ìŠˆ ê´€ë ¨ íŠ¸ìœ— ìˆ˜ì§‘
    query = 'ë°ì´ì‹ìŠ¤ ë³¸ì¸í™•ì¸ -ì–‘ë„ -íŒë§¤ -êµ¬ë§¤ -ëŒ€ë¦¬ -êµí™˜ -íŒ¬ì‹¸ì»· -í•­ê³µí¸'

    print("íŠ¸ìœ„í„° ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 50)

    tweets = collect_tweets(query, max_results=50, start_date='2025-07-22', end_date='2025-07-24')

    if tweets:
        save_tweets(tweets, 'dayx6_tweets.json')
        analyze_tweets_preview(tweets)
    else:
        print("âŒ ìˆ˜ì§‘ëœ íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤")