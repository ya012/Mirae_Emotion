# -*- coding: utf-8 -*-
"""
SNS ê°ì •ë¶„ì„ ëª¨ë“ˆ (ê°œì„  ë²„ì „)
"""
import json
import requests
import uuid
from collections import Counter
import os
from dotenv import load_dotenv
import streamlit as st
from datetime import datetime

load_dotenv()


def get_api_key():
    """API í‚¤ íšë“ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” Streamlit secrets)"""
    api_key = os.getenv('CLOVA_API_KEY')

    # Streamlit secretsì—ì„œë„ ì‹œë„
    if not api_key and hasattr(st, 'secrets'):
        try:
            api_key = st.secrets.get('CLOVA_API_KEY')
        except:
            pass

    return api_key


def analyze_single_tweet(tweet_text, news_context, stock_symbol, api_key):
    """ë‹¨ì¼ íŠ¸ìœ— ê°ì •ë¶„ì„ (ê°œì„  ë²„ì „)"""
    if not api_key:
        # API ì—†ì„ ë•Œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        positive_keywords = ['ì¢‹', 'ì‘ì›', 'ì‚¬ë‘', 'ìµœê³ ', 'ëŒ€ë°•', 'ê°ì‚¬', 'í™”ì´íŒ…']
        negative_keywords = ['ì‹«', 'ì‹¤ë§', 'í™”', 'ìµœì•…', 'ë¬¸ì œ', 'ë¹„íŒ', 'ë°˜ëŒ€']

        text_lower = tweet_text.lower()
        pos_count = sum(1 for word in positive_keywords if word in text_lower)
        neg_count = sum(1 for word in negative_keywords if word in text_lower)

        if pos_count > neg_count:
            return 'ê¸ì •'
        elif neg_count > pos_count:
            return 'ë¶€ì •'
        return 'ì¤‘ë¦½'

    request_id = str(uuid.uuid4()).replace('-', '')

    headers_list = [
        {
            'Authorization': api_key,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        },
        {
            'Authorization': f'Bearer {api_key}',
            'X-NCP-CLOVASTUDIO-REQUEST-ID': request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }
    ]

    system_prompt = f"""ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ ê°ì •ë¶„ì„ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ ì´ìŠˆ: {news_context}

ìœ„ ì´ìŠˆê°€ {stock_symbol} ì¢…ëª©ì— ë¯¸ì¹  ì˜í–¥ì„ ê³ ë ¤í•˜ì—¬ íŠ¸ìœ—ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”: ê¸ì •, ë¶€ì •, ì¤‘ë¦½

íŒë‹¨ ê¸°ì¤€:
- ê¸ì •: {stock_symbol}/ì•„í‹°ìŠ¤íŠ¸ì— ëŒ€í•œ ì§€ì§€, ì‘ì›, ì˜¹í˜¸, ì§€ì› í‘œí˜„
- ë¶€ì •: ì‹¤ë§, ë¹„íŒ, ìš°ë ¤, í™˜ë©¸, ë¶ˆë§Œ ë“± ë¶€ì •ì  ê°ì • í‘œí˜„  
- ì¤‘ë¦½: ë‹¨ìˆœ ì‚¬ì‹¤ ì „ë‹¬, ê´€ë ¨ ì—†ëŠ” ë‚´ìš©, ì• ë§¤í•œ í‘œí˜„

ê°ì • í•˜ë‚˜ë§Œ ë‹µí•˜ê³  ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"íŠ¸ìœ—: {tweet_text[:500]}"}  # ê¸¸ì´ ì œí•œ
    ]

    request_data = {
        'messages': messages,
        'topP': 0.3,
        'topK': 0,
        'maxTokens': 5,
        'temperature': 0.1,
        'repetitionPenalty': 1.2,
        'stop': [],
        'includeAiFilters': True,
        'seed': 0
    }

    # ì—¬ëŸ¬ í—¤ë”ë¡œ ì‹œë„
    for headers in headers_list:
        try:
            with requests.post(
                    'https://clovastudio.stream.ntruss.com/v3/chat-completions/HCX-005',
                    headers=headers,
                    json=request_data,
                    stream=True,
                    timeout=15
            ) as r:

                if r.status_code != 200:
                    continue

                for line in r.iter_lines():
                    if line:
                        line_text = line.decode("utf-8")
                        if line_text.startswith('data:'):
                            try:
                                data = json.loads(line_text[5:])
                                if 'message' in data and data['message'].get('content'):
                                    if data.get('finishReason') == 'stop':
                                        sentiment = data['message']['content'].strip()
                                        if 'ê¸ì •' in sentiment:
                                            return 'ê¸ì •'
                                        elif 'ë¶€ì •' in sentiment:
                                            return 'ë¶€ì •'
                                        else:
                                            return 'ì¤‘ë¦½'
                            except:
                                continue

        except Exception as e:
            continue

    return 'ì¤‘ë¦½'


def generate_reaction_summary(sentiment_counts, sample_tweets, investor_type, api_key):
    """SNS ë°˜ì‘ ìš”ì•½ ë¬¸ì¥ ìƒì„± (ê°œì„  ë²„ì „)"""
    total = sum(sentiment_counts.values())
    if total == 0:
        return "ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    percentages = {k: (v / total) * 100 for k, v in sentiment_counts.items()}
    dominant_sentiment = max(percentages, key=percentages.get)

    # API ì—†ì„ ë•Œ ê¸°ë³¸ ìš”ì•½
    if not api_key:
        return get_fallback_reaction_summary(percentages, dominant_sentiment, investor_type)

    request_id = str(uuid.uuid4()).replace('-', '')
    headers = {
        'Authorization': api_key,
        'X-NCP-CLOVASTUDIO-REQUEST-ID': request_id,
        'Content-Type': 'application/json; charset=utf-8',
        'Accept': 'text/event-stream'
    }

    # íˆ¬ìì ìœ í˜•ë³„ ë” ëª…í™•í•œ í”„ë¡¬í”„íŠ¸
    if investor_type == "MIRAE":
        system_prompt = f"""ë‹¹ì‹ ì€ SNS ë°˜ì‘ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

MIRAEí˜• ì¥ê¸° íˆ¬ììë¥¼ ìœ„í•´ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ì£¼ë„ì  ê°ì •: {dominant_sentiment}**

ìš”ì•½ ë°©ì‹:
- ê°ì • ë¹„ìœ¨ê³¼ ì£¼ìš” ë°˜ì‘ íŒ¨í„´ì„ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ 
- ì¤‘ë¦½ì ì´ê³  ë¶„ì„ì ì¸ í†¤ ìœ ì§€
- 3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ì¥ê¸°ì  ê´€ì ì—ì„œì˜ ì—¬ë¡  íë¦„ ë¶„ì„

ì ˆëŒ€ íˆ¬ì ì¡°ì–¸ì€ í•˜ì§€ ë§ê³  ê°ê´€ì  ë¶„ì„ë§Œ ì œê³µí•˜ì„¸ìš”."""

    else:  # ASAPí˜•
        system_prompt = f"""ë‹¹ì‹ ì€ SNS ë°˜ì‘ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ASAPí˜• ë‹¨ê¸° íˆ¬ììë¥¼ ìœ„í•´ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„¸íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ì£¼ë„ì  ê°ì •: {dominant_sentiment}**

ìš”ì•½ ë°©ì‹:
- ê° ê°ì •ì˜ ê°•ë„ì™€ í‘œí˜„ ë°©ì‹ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- ì£¼ìš” í‚¤ì›Œë“œì™€ ë°˜ì‘ íŒ¨í„´ì„ ìì„¸íˆ ì–¸ê¸‰
- ë‹¤ì–‘í•œ ì˜ê²¬ë“¤ì˜ ë‰˜ì•™ìŠ¤ì™€ ë³€í™” ì¶”ì´ í¬í•¨
- 5-6ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±
- SNS íŠ¹ì„±ì„ ë°˜ì˜í•œ ìƒìƒí•œ í‘œí˜„ ì‚¬ìš©

ì ˆëŒ€ íˆ¬ì ì¡°ì–¸ì€ í•˜ì§€ ë§ê³  ë°˜ì‘ ë¶„ì„ë§Œ ì œê³µí•˜ì„¸ìš”."""

    # ìƒ˜í”Œ íŠ¸ìœ— ì •ë¦¬
    tweet_samples = []
    for sentiment, tweets in sample_tweets.items():
        if tweets:
            sample_text = tweets[0]['text'][:80].replace('\n', ' ')
            tweet_samples.append(f"{sentiment}: {sample_text}")

    user_content = f"""
ê°ì • ë¹„ìœ¨:
- ê¸ì •: {percentages.get('ê¸ì •', 0):.1f}%
- ë¶€ì •: {percentages.get('ë¶€ì •', 0):.1f}%  
- ì¤‘ë¦½: {percentages.get('ì¤‘ë¦½', 0):.1f}%

ëŒ€í‘œ ë°˜ì‘:
{chr(10).join(tweet_samples[:3])}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëŒ€ì¤‘ì˜ SNS ë°˜ì‘ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content}
    ]

    request_data = {
        'messages': messages,
        'topP': 0.8,
        'topK': 0,
        'maxTokens': 300 if investor_type == "MIRAE" else 500,
        'temperature': 0.3,
        'repetitionPenalty': 1.1,
        'stop': [],
        'includeAiFilters': True,
        'seed': 0
    }

    try:
        with requests.post(
                'https://clovastudio.stream.ntruss.com/v3/chat-completions/HCX-005',
                headers=headers,
                json=request_data,
                stream=True,
                timeout=25
        ) as r:

            if r.status_code != 200:
                return get_fallback_reaction_summary(percentages, dominant_sentiment, investor_type)

            for line in r.iter_lines():
                if line:
                    line_text = line.decode("utf-8")
                    if line_text.startswith('data:'):
                        try:
                            data = json.loads(line_text[5:])
                            if 'message' in data and data['message'].get('content'):
                                if data.get('finishReason') == 'stop':
                                    return data['message']['content']
                        except:
                            continue

    except Exception as e:
        print(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")

    return get_fallback_reaction_summary(percentages, dominant_sentiment, investor_type)


def get_fallback_reaction_summary(percentages, dominant_sentiment, investor_type):
    """API ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ìš”ì•½"""
    pos_pct = percentages.get('ê¸ì •', 0)
    neg_pct = percentages.get('ë¶€ì •', 0)
    neu_pct = percentages.get('ì¤‘ë¦½', 0)

    if investor_type == "MIRAE":
        return f"""ë¶„ì„ ê²°ê³¼ {dominant_sentiment}ì  ë°˜ì‘ì´ {percentages[dominant_sentiment]:.1f}%ë¡œ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ê¸ì • {pos_pct:.1f}%, ë¶€ì • {neg_pct:.1f}%, ì¤‘ë¦½ {neu_pct:.1f}%ì˜ ë¶„í¬ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ íŒ¬ë“¤ì˜ ê°ì •ì´ ëšœë ·í•˜ê²Œ ë¶„í™”ë˜ì–´ ìˆìœ¼ë©°, í–¥í›„ ê¸°ì—… ëŒ€ì‘ì— ë”°ë¼ ì—¬ë¡  ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."""
    else:  # ASAPí˜•
        if dominant_sentiment == "ë¶€ì •":
            return f"""SNSì—ì„œ ê°•í•œ ë¶€ì •ì  ë°˜ì‘ì´ {neg_pct:.1f}%ë¡œ ì§€ë°°ì ì…ë‹ˆë‹¤. íŒ¬ë“¤ì€ 'ê°œì¸ì •ë³´ ì¹¨í•´', 'ê³¼ë„í•œ ìš”êµ¬'ë¼ëŠ” í‚¤ì›Œë“œë¡œ ë¹„íŒí•˜ê³  ìˆìœ¼ë©°, ì¼ë¶€ì—ì„œëŠ” ë³´ì´ì½§ ì›€ì§ì„ë„ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸ì •ì  ë°˜ì‘ì€ {pos_pct:.1f}%ì— ê·¸ì³ ì „ë°˜ì ìœ¼ë¡œ ë¶€ì •ì  ì—¬ë¡ ì´ ìš°ì„¸í•œ ìƒí™©ì…ë‹ˆë‹¤. ë¹ ë¥¸ í•´ëª…ì´ë‚˜ ê°œì„ ì±… ë°œí‘œê°€ ì—†ë‹¤ë©´ ë¶€ì • ì—¬ë¡ ì´ ë”ìš± í™•ì‚°ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."""
        else:
            return f"""{dominant_sentiment}ì  ë°˜ì‘ì´ {percentages[dominant_sentiment]:.1f}%ë¡œ ìš°ì„¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì˜ê²¬ì´ í‘œì¶œë˜ê³  ìˆìœ¼ë©°, íŒ¬ë¤ ë‚´ì—ì„œë„ ì˜ê²¬ì´ ë¶„í™”ë˜ëŠ” ì–‘ìƒì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì—¬ë¡ ì´ ë³€í™”í•˜ê³  ìˆì–´ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤."""


def analyze_sns_sentiment(tweets_file, news_context, stock_symbol, investor_type="MIRAE", max_tweets=20):
    """SNS ê°ì •ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ (ê°œì„  ë²„ì „)"""

    # íŠ¸ìœ— ë°ì´í„° ë¡œë“œ
    try:
        with open(tweets_file, 'r', encoding='utf-8') as f:
            tweets_data = json.load(f)
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {tweets_file}")
        # ëŒ€ì²´ ë°ì´í„° ë°˜í™˜
        return get_fallback_sns_result(investor_type)

    if not tweets_data:
        return get_fallback_sns_result(investor_type)

    api_key = get_api_key()
    print(f"API í‚¤ ìƒíƒœ: {'ìˆìŒ' if api_key else 'ì—†ìŒ'}")

    # ìƒìœ„ íŠ¸ìœ— ë¶„ì„ (ì¸ê²Œì´ì§€ë¨¼íŠ¸ ê¸°ì¤€)
    sorted_tweets = sorted(
        tweets_data,
        key=lambda x: x.get('like_count', 0) + x.get('retweet_count', 0),
        reverse=True
    )

    results = []
    print(f"ğŸ¤– [{investor_type}í˜•] SNS ê°ì •ë¶„ì„ ì‹œì‘... (ìµœëŒ€ {max_tweets}ê°œ)")

    for i, tweet in enumerate(sorted_tweets[:max_tweets]):
        try:
            sentiment = analyze_single_tweet(
                tweet['text'], news_context, stock_symbol, api_key
            )

            results.append({
                'tweet_id': tweet.get('id', f'tweet_{i}'),
                'text': tweet['text'],
                'sentiment': sentiment,
                'like_count': tweet.get('like_count', 0),
                'retweet_count': tweet.get('retweet_count', 0)
            })

            if (i + 1) % 5 == 0:
                print(f"   ì§„í–‰: {i + 1}/{max_tweets} ì™„ë£Œ")

        except Exception as e:
            print(f"íŠ¸ìœ— {i + 1} ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¤‘ë¦½ ì²˜ë¦¬
            results.append({
                'tweet_id': f'tweet_{i}',
                'text': tweet.get('text', ''),
                'sentiment': 'ì¤‘ë¦½',
                'like_count': tweet.get('like_count', 0),
                'retweet_count': tweet.get('retweet_count', 0)
            })

    # ê²°ê³¼ ì§‘ê³„
    sentiments = [r['sentiment'] for r in results]
    sentiment_counts = Counter(sentiments)

    total = len(results)
    percentages = {
        'ê¸ì •': (sentiment_counts.get('ê¸ì •', 0) / total * 100) if total > 0 else 0,
        'ë¶€ì •': (sentiment_counts.get('ë¶€ì •', 0) / total * 100) if total > 0 else 0,
        'ì¤‘ë¦½': (sentiment_counts.get('ì¤‘ë¦½', 0) / total * 100) if total > 0 else 0
    }

    # ëŒ€í‘œ íŠ¸ìœ— ì„ ë³„
    sample_tweets = {
        'ê¸ì •': [r for r in results if r['sentiment'] == 'ê¸ì •'][:2],
        'ë¶€ì •': [r for r in results if r['sentiment'] == 'ë¶€ì •'][:2],
        'ì¤‘ë¦½': [r for r in results if r['sentiment'] == 'ì¤‘ë¦½'][:2]
    }

    # ë°˜ì‘ ìš”ì•½ ìƒì„±
    print(f"ğŸ“ [{investor_type}í˜•] ë°˜ì‘ ìš”ì•½ ìƒì„± ì¤‘...")
    reaction_summary = generate_reaction_summary(
        sentiment_counts, sample_tweets, investor_type, api_key
    )

    print(f"âœ… [{investor_type}í˜•] SNS ë¶„ì„ ì™„ë£Œ!")

    return {
        'success': True,
        'percentages': percentages,
        'sentiment_counts': sentiment_counts,
        'total_analyzed': total,
        'sample_tweets': sample_tweets,
        'reaction_summary': reaction_summary,
        'detailed_results': results,
        'investor_type': investor_type,
        'api_used': bool(api_key)
    }


def get_fallback_sns_result(investor_type):
    """ëŒ€ì²´ SNS ë¶„ì„ ê²°ê³¼"""
    if investor_type == "MIRAE":
        percentages = {"ê¸ì •": 22.1, "ë¶€ì •": 64.3, "ì¤‘ë¦½": 13.6}
        reaction_summary = "ë¶„ì„ ê²°ê³¼ ë¶€ì •ì  ë°˜ì‘ì´ 64.3%ë¡œ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ê¸ì • 22.1%, ë¶€ì • 64.3%, ì¤‘ë¦½ 13.6%ì˜ ë¶„í¬ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ íŒ¬ë“¤ì˜ ê°ì •ì´ ëšœë ·í•˜ê²Œ ë¶„í™”ë˜ì–´ ìˆìœ¼ë©°, í–¥í›„ ê¸°ì—… ëŒ€ì‘ì— ë”°ë¼ ì—¬ë¡  ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."
    else:  # ASAPí˜•
        percentages = {"ê¸ì •": 24.3, "ë¶€ì •": 61.8, "ì¤‘ë¦½": 13.9}
        reaction_summary = "SNSì—ì„œ ê°•í•œ ë¶€ì •ì  ë°˜ì‘ì´ 61.8%ë¡œ ì§€ë°°ì ì…ë‹ˆë‹¤. íŒ¬ë“¤ì€ 'ê°œì¸ì •ë³´ ì¹¨í•´', 'ê³¼ë„í•œ ìš”êµ¬'ë¼ëŠ” í‚¤ì›Œë“œë¡œ ë¹„íŒí•˜ê³  ìˆìœ¼ë©°, ì¼ë¶€ì—ì„œëŠ” ë³´ì´ì½§ ì›€ì§ì„ë„ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸ì •ì  ë°˜ì‘ì€ 24.3%ì— ê·¸ì³ ì „ë°˜ì ìœ¼ë¡œ ë¶€ì •ì  ì—¬ë¡ ì´ ìš°ì„¸í•œ ìƒí™©ì…ë‹ˆë‹¤. ë¹ ë¥¸ í•´ëª…ì´ë‚˜ ê°œì„ ì±… ë°œí‘œê°€ ì—†ë‹¤ë©´ ë¶€ì • ì—¬ë¡ ì´ ë”ìš± í™•ì‚°ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."

    return {
        'success': True,
        'percentages': percentages,
        'sentiment_counts': {
            'ê¸ì •': int(percentages['ê¸ì •'] * 20 / 100),
            'ë¶€ì •': int(percentages['ë¶€ì •'] * 20 / 100),
            'ì¤‘ë¦½': int(percentages['ì¤‘ë¦½'] * 20 / 100)
        },
        'total_analyzed': 20,
        'sample_tweets': {
            'ê¸ì •': [{'text': 'ê·¸ë˜ë„ ë°ì‹ì´ë“¤ ì‘ì›í•´', 'sentiment': 'ê¸ì •'}],
            'ë¶€ì •': [{'text': 'ì´ê±´ ë„ˆë¬´ ê³¼í•˜ë‹¤ ê°œì¸ì •ë³´ ì™œ ìš”êµ¬í•´', 'sentiment': 'ë¶€ì •'}],
            'ì¤‘ë¦½': [{'text': 'ìƒí™© ì§€ì¼œë³´ì', 'sentiment': 'ì¤‘ë¦½'}]
        },
        'reaction_summary': reaction_summary,
        'detailed_results': [],
        'investor_type': investor_type,
        'api_used': False,
        'source': 'fallback'
    }


def get_day6_sns_analysis(news_context, investor_type="MIRAE"):
    """ë°ì´ì‹ìŠ¤ ë³¸ì¸í™•ì¸ ì´ìŠˆ SNS ë¶„ì„ (ìºì‹œ ì§€ì›)"""
    tweets_file = "data/day6_tweets.json"

    # ìºì‹œ í™•ì¸
    cache_file = f"data/sns_cache_{investor_type.lower()}.json"

    try:
        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                cached_data = json.load(f)
                # ìºì‹œê°€ 1ì‹œê°„ ì´ë‚´ë¼ë©´ ì‚¬ìš©
                cache_time = datetime.fromisoformat(cached_data.get('timestamp', '2000-01-01'))
                if (datetime.now() - cache_time).seconds < 3600:
                    print(f"ìºì‹œëœ {investor_type}í˜• SNS ë¶„ì„ ì‚¬ìš©")
                    return cached_data['data']
    except:
        pass

    # ìƒˆë¡œ ë¶„ì„
    result = analyze_sns_sentiment(tweets_file, news_context, "JYP", investor_type, max_tweets=15)

    # ìºì‹œ ì €ì¥
    if result.get('success'):
        try:
            os.makedirs('data', exist_ok=True)
            cache_data = {
                'timestamp': datetime.now().isoformat(),
                'data': result
            }
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except:
            pass

    return result


def test_sns_analysis():
    """SNS ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("SNS ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    news_context = "ë°ì´ì‹ìŠ¤ íŒ¬ë¯¸íŒ…ì—ì„œ ê³¼ë„í•œ ë³¸ì¸í™•ì¸ ì ˆì°¨ë¡œ ì¸í•œ íŒ¬ë“¤ì˜ ë°˜ë°œ"

    for investor_type in ["MIRAE", "ASAP"]:
        print(f"\n=== {investor_type}í˜• í…ŒìŠ¤íŠ¸ ===")
        result = get_day6_sns_analysis(news_context, investor_type)

        if result.get('success'):
            print(f"ì„±ê³µ: {result.get('source', 'api')}")
            print(f"ë¶„ì„ ê°œìˆ˜: {result['total_analyzed']}ê°œ")
            print(f"ê°ì • ë¹„ìœ¨: {result['percentages']}")
            print(f"ìš”ì•½: {result['reaction_summary'][:100]}...")
        else:
            print(f"ì‹¤íŒ¨: {result.get('error', 'unknown error')}")


if __name__ == "__main__":
    test_sns_analysis()